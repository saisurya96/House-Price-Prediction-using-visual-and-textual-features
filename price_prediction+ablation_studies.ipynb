{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1c42900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb429023",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = np.load(r'img_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764dd361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 20480)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def l2_convert(row):\n",
    "    l2_imgs = []\n",
    "    jump = int(len(row)/5)\n",
    "    for i in range(0, len(row), jump):\n",
    "        img = row[i:i+jump]\n",
    "        img_norm = np.linalg.norm(img)\n",
    "        img_normalized = img/img_norm\n",
    "        l2_imgs.extend(img_normalized)\n",
    "    return l2_imgs\n",
    "\n",
    "#computing and appending l2 norm of each image for each house(2000)\n",
    "img_data_l2 = list(map(l2_convert, img_data))\n",
    "\n",
    "# print(str(len(img_data_l2)), 'x', str(len(img_data_l2[0])))\n",
    "img_data_l2 = np.asarray(img_data_l2)\n",
    "img_data_l2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabd5947",
   "metadata": {},
   "source": [
    "# Splitting each image into a different set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2f750c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 4096)\n",
      "(3000, 4096)\n",
      "(3000, 4096)\n",
      "(3000, 4096)\n",
      "(3000, 4096)\n"
     ]
    }
   ],
   "source": [
    "#1st image- Bathroom\n",
    "img_data_1 = img_data_l2[:, 0:4096]\n",
    "\n",
    "#2nd image- bedroom\n",
    "img_data_2 = img_data_l2[:, 4096:8192]\n",
    "\n",
    "#3rd image- Living room\n",
    "img_data_3 = img_data_l2[:, 8192:12288]\n",
    "\n",
    "#4th image- Kitchen\n",
    "img_data_4 = img_data_l2[:, 12288:16384]\n",
    "\n",
    "#5th image- Exterior\n",
    "img_data_5 = img_data_l2[:, 16384:20480]\n",
    "\n",
    "print(img_data_1.shape)\n",
    "print(img_data_2.shape)\n",
    "print(img_data_3.shape)\n",
    "print(img_data_4.shape)\n",
    "print(img_data_5.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434916f4",
   "metadata": {},
   "source": [
    "# Importing Tabular data and Target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f416f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(r'final_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d6c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 11)\n"
     ]
    }
   ],
   "source": [
    "tab_data  = data[:, :11]\n",
    "print(tab_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3efc010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "#Importing target\n",
    "y = np.load(r'target.npy')\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b650212e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97524f03",
   "metadata": {},
   "source": [
    "# Computing kernel and calculating error for 1st image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81920540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "img1_train, img1_test, y_train, y_test = train_test_split(img_data_1, y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835a939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building training kernel\n",
    "mlk_img1_train = np.dot(img1_train, img1_train.transpose())\n",
    "\n",
    "# building testing kernel\n",
    "mlk_img1_test = np.dot(img1_test, img1_train.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0247588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping target\n",
    "y_train = y_train.reshape(2700)\n",
    "y_test = y_test.reshape(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6d8bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with 1st image kernel: 20.39391857435239\n"
     ]
    }
   ],
   "source": [
    "#initiating SVR Object\n",
    "svr1 = SVR(kernel= 'precomputed')\n",
    "\n",
    "#fitting the SVR model\"\n",
    "svr1.fit(mlk_img1_train, y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred1 = svr1.predict(mlk_img1_test)\n",
    "\n",
    "error1 = mean_absolute_error(y_test, np.absolute(y_pred1))\n",
    "print('Error with 1st image kernel:', error1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45474e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc6e3c93",
   "metadata": {},
   "source": [
    "# Computing kernel and calculating error for 2st image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac80176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "img2_train, img2_test, y_train, y_test = train_test_split(img_data_2, y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "216e8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building training kernel\n",
    "mlk_img2_train = np.dot(img2_train, img2_train.transpose())\n",
    "\n",
    "# building testing kernel\n",
    "mlk_img2_test = np.dot(img2_test, img2_train.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16fa10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping target\n",
    "y_train = y_train.reshape(2700)\n",
    "y_test = y_test.reshape(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aeea6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with 2nd image kernel: 19.45732681804665\n"
     ]
    }
   ],
   "source": [
    "#initiating SVR Object\n",
    "svr2 = SVR(kernel= 'precomputed')\n",
    "\n",
    "#fitting the SVR model\"\n",
    "svr2.fit(mlk_img2_train, y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred2 = svr2.predict(mlk_img2_test)\n",
    "\n",
    "error2 = mean_absolute_error(y_test, np.absolute(y_pred2))\n",
    "print('Error with 2nd image kernel:', error2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6f3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "052a38d9",
   "metadata": {},
   "source": [
    "# Computing kernel and calculating error for 3rd image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c5f0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "img3_train, img3_test, y_train, y_test = train_test_split(img_data_3, y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "884ed669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building training kernel\n",
    "mlk_img3_train = np.dot(img3_train, img3_train.transpose())\n",
    "\n",
    "# building testing kernel\n",
    "mlk_img3_test = np.dot(img3_test, img3_train.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a626c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping target\n",
    "y_train = y_train.reshape(2700)\n",
    "y_test = y_test.reshape(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5774b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with 3rd image kernel: 19.107499758431175\n"
     ]
    }
   ],
   "source": [
    "#initiating SVR Object\n",
    "svr3 = SVR(kernel= 'precomputed')\n",
    "\n",
    "#fitting the SVR model\"\n",
    "svr3.fit(mlk_img3_train, y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred3 = svr3.predict(mlk_img3_test)\n",
    "\n",
    "error3 = mean_absolute_error(y_test, np.absolute(y_pred3))\n",
    "print('Error with 3rd image kernel:', error3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8452e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc69048a",
   "metadata": {},
   "source": [
    "# Computing kernel and calculating error for 4th image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87e9ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "img4_train, img4_test, y_train, y_test = train_test_split(img_data_4, y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64041ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building training kernel\n",
    "mlk_img4_train = np.dot(img4_train, img4_train.transpose())\n",
    "\n",
    "# building testing kernel\n",
    "mlk_img4_test = np.dot(img4_test, img4_train.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe216c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping target\n",
    "y_train = y_train.reshape(2700)\n",
    "y_test = y_test.reshape(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97b4d897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with 4th image kernel: 19.199402758065656\n"
     ]
    }
   ],
   "source": [
    "#initiating SVR Object\n",
    "svr4 = SVR(kernel= 'precomputed')\n",
    "\n",
    "#fitting the SVR model\"\n",
    "svr4.fit(mlk_img4_train, y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred4 = svr4.predict(mlk_img4_test)\n",
    "\n",
    "error4 = mean_absolute_error(y_test, np.absolute(y_pred4))\n",
    "print('Error with 4th image kernel:', error4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37008fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ef1116e",
   "metadata": {},
   "source": [
    "# Computing kernel and calculating error for 5th image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50203477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "img5_train, img5_test, y_train, y_test = train_test_split(img_data_5, y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32f09cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building training kernel\n",
    "mlk_img5_train = np.dot(img1_train, img5_train.transpose())\n",
    "\n",
    "# building testing kernel\n",
    "mlk_img5_test = np.dot(img1_test, img5_train.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3173e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping target\n",
    "y_train = y_train.reshape(2700)\n",
    "y_test = y_test.reshape(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bb56c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with 5th image kernel: 25.5088341964973\n"
     ]
    }
   ],
   "source": [
    "#initiating SVR Object\n",
    "svr5 = SVR(kernel= 'precomputed')\n",
    "\n",
    "#fitting the SVR model\n",
    "svr5.fit(mlk_img5_train, y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred5 = svr5.predict(mlk_img5_test)\n",
    "\n",
    "error5 = mean_absolute_error(y_test, np.absolute(y_pred5))\n",
    "print('Error with 5th image kernel:', error5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1200f0",
   "metadata": {},
   "source": [
    "# Computing kernel and calculating error for tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c3efa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "tab_train, tab_test, y_train, y_test = train_test_split(tab_data, y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ce7ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building training kernel\n",
    "mlk_tab_train = np.dot(tab_train, tab_train.transpose())\n",
    "\n",
    "# building testing kernel\n",
    "mlk_tab_test = np.dot(tab_test, tab_train.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1a15c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping target\n",
    "y_train = y_train.reshape(2700)\n",
    "y_test = y_test.reshape(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db165872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with tabular data kernel: 19.740835358184178\n"
     ]
    }
   ],
   "source": [
    "#initiating SVR Object\n",
    "svr_tab = SVR(kernel= 'precomputed')\n",
    "\n",
    "#fitting the SVR model\"\n",
    "svr_tab.fit(mlk_tab_train, y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred_tab = svr_tab.predict(mlk_tab_test)\n",
    "\n",
    "error6 = mean_absolute_error(y_test, np.absolute(y_pred_tab))\n",
    "print('Error with tabular data kernel:', error6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa0c80",
   "metadata": {},
   "source": [
    "# Printing Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba9fca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with 1st image (bathroom) kernel:\t\t 20.39391857435239\n",
      "Error with 2nd image (bedroom) kernel:\t\t 19.45732681804665\n",
      "Error with 3rd image (living room) kernel:\t 19.107499758431175\n",
      "Error with 4th image (kitchen) kernel:\t\t 19.199402758065656\n",
      "Error with 5th image (exterior) kernel:\t\t 25.5088341964973\n",
      "Error with tabular data kernel:\t\t\t 19.740835358184178\n"
     ]
    }
   ],
   "source": [
    "print('Error with 1st image (bathroom) kernel:\\t\\t', error1)\n",
    "print('Error with 2nd image (bedroom) kernel:\\t\\t', error2)\n",
    "print('Error with 3rd image (living room) kernel:\\t', error3)\n",
    "print('Error with 4th image (kitchen) kernel:\\t\\t', error4)\n",
    "print('Error with 5th image (exterior) kernel:\\t\\t', error5)\n",
    "print('Error with tabular data kernel:\\t\\t\\t', error6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01538db",
   "metadata": {},
   "source": [
    "# Further Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ee87c",
   "metadata": {},
   "source": [
    "## Testing with a single kernel for entire dataset (table+images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "397e437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = np.load(r'final_data.npy')\n",
    "y = np.load(r'target.npy')\n",
    "\n",
    "# to convert to l2-norm\n",
    "def tab_l2_convert(row):\n",
    "    row_norm = np.linalg.norm(row)\n",
    "    return row/row_norm \n",
    "\n",
    "data_l2 = list(map(tab_l2_convert, data_full))\n",
    "data_l2 = np.asarray(data_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97e11aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "data_train, data_test, y_train, y_test = train_test_split(data_l2, y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "497fd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building training kernel\n",
    "lk_data_train = np.dot(data_train, data_train.transpose())\n",
    "\n",
    "# building testing kernel\n",
    "lk_data_test = np.dot(data_test, data_train.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a61bfd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping target\n",
    "y_train = y_train.reshape(2700)\n",
    "y_test = y_test.reshape(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "805c690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with full data (single kernel): 22.370196306639706\n"
     ]
    }
   ],
   "source": [
    "#initiating SVR Object\n",
    "svr_full = SVR(kernel= 'precomputed')\n",
    "\n",
    "#fitting the SVR model\"\n",
    "svr_full.fit(lk_data_train, y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred_full = svr_tab.predict(lk_data_test)\n",
    "\n",
    "error = mean_absolute_error(y_test, np.absolute(y_pred_full))\n",
    "print('Error with full data (single kernel):', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc576465",
   "metadata": {},
   "source": [
    "## Baseline 1 -Testing with full data without kernel using SVM (tab+images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e4d064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.shape\n",
    "#Train test split\n",
    "data_full_train, data_full_test, y_train, y_test = train_test_split(data_full, y, test_size = 0.1, random_state = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0c211a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with full data (linear SVR): 17.950984676916963\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(kernel= 'linear', C = 10, epsilon = 25)\n",
    "\n",
    "#fitting the SVR model\"\n",
    "svr.fit(data_full_train, y_train)\n",
    "\n",
    "#prediction\n",
    "y_pred_full = svr.predict(data_full_test)\n",
    "\n",
    "error = mean_absolute_error(y_test, np.absolute(y_pred_full))\n",
    "print('Error with full data (linear SVR):', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e069fcc7",
   "metadata": {},
   "source": [
    "## Baseline 2 - Non Negative Linear Regression with all attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6ebc020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22676/651165333.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlsqnonn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlsqnonn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_full_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlsqnonn_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlsqnonn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_full_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_residues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;31m# scipy.optimize.nnls cannot handle y with shape (M, K)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_nnls.py\u001b[0m in \u001b[0;36mnnls\u001b[1;34m(A, b, maxiter)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__nnls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"too many iterations\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lsqnonn = LinearRegression(positive = True)\n",
    "lsqnonn.fit(data_full_train, y_train)\n",
    "lsqnonn_pred = lsqnonn.predict(data_full_test)\n",
    "\n",
    "error_lsqnonn = mean_absolute_error(y_test, np.absolute(lsqnonn_pred))\n",
    "print('Error with full data (non-negative least squares):', error_lsqnonn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e274b",
   "metadata": {},
   "source": [
    "## Baseline 3 - Linear Regression with all attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83efa16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with full data (linear regression): 20.577916287352284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(data_full_train, y_train)\n",
    "lr_pred = lr.predict(data_full_test)\n",
    "\n",
    "error_lr = mean_absolute_error(y_test, np.absolute(lr_pred))\n",
    "print('Error with full data (linear regression):', error_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8475d3",
   "metadata": {},
   "source": [
    "## Baseline 4 - K- Nearest neighbord with all attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44110718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with full data (nearest neighbors): 17.914920153846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "neigh = KNeighborsRegressor(n_neighbors=13, algorithm = 'brute')\n",
    "neigh.fit(data_full_train, y_train)\n",
    "neigh_pred = neigh.predict(data_full_test)\n",
    "\n",
    "error_neigh = mean_absolute_error(y_test, np.absolute(neigh_pred))\n",
    "print('Error with full data (nearest neighbors):', error_neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3f01c8",
   "metadata": {},
   "source": [
    "# saving kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10c28e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mlk_img1_train).to_csv(\"mlk_img1_train.csv\", header = False, index = False)\n",
    "pd.DataFrame(mlk_img2_train).to_csv(\"mlk_img2_train.csv\", header = False, index = False)\n",
    "pd.DataFrame(mlk_img3_train).to_csv(\"mlk_img3_train.csv\", header = False, index = False)\n",
    "pd.DataFrame(mlk_img4_train).to_csv(\"mlk_img4_train.csv\", header = False, index = False)\n",
    "pd.DataFrame(mlk_img5_train).to_csv(\"mlk_img5_train.csv\", header = False, index = False)\n",
    "pd.DataFrame(mlk_tab_train).to_csv(\"mlk_tab_train.csv\", header = False, index = False)\n",
    "\n",
    "pd.DataFrame(mlk_img1_test).to_csv(\"mlk_img1_test.csv\", header = False, index = False)\n",
    "pd.DataFrame(mlk_img2_test).to_csv(\"mlk_img2_test.csv\", header = False, index = False)\n",
    "pd.DataFrame(mlk_img3_test).to_csv(\"mlk_img3_test.csv\", header = False, index = False)\n",
    "pd.DataFrame(mlk_img4_test).to_csv(\"mlk_img4_test.csv\", header = False, index = False)\n",
    "pd.DataFrame(mlk_img5_test).to_csv(\"mlk_img5_test.csv\", header = False, index = False)\n",
    "pd.DataFrame(mlk_tab_test).to_csv(\"mlk_tab_test.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6bfa3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
